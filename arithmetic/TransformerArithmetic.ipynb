{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ygmAHr3xHJUj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import wandb\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hS_WEb7nJs9L"
   },
   "source": [
    "## Some parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1x_0ceefJr9A",
    "outputId": "b26d4229-88a1-42f9-8fbc-583d694f398f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "  # dataset\n",
    "  \"digits\": 4,\n",
    "  \"highest_number\": 33,\n",
    "  \"train_size\": 10000,\n",
    "  \"test_size\": 1000,\n",
    "  # learning\n",
    "  \"learning_rate\": 5e-5,\n",
    "  \"num_warmup_steps\": 100,\n",
    "  \"num_epochs\": 150,\n",
    "  \"batch_size\": 64,\n",
    "  \"num_warmup_epochs\": 40,\n",
    "  # loops\n",
    "  \"eval_freq\": 50,\n",
    "  # model\n",
    "  \"num_attention_heads\": 1,\n",
    "  \"num_hidden_layers\": 6,\n",
    "  \"alignments2\": [\n",
    "        [[-1,1], \"w\"],\n",
    "        [[-1,2], \"x\"],\n",
    "        [[-1,3], \"y\"],\n",
    "        [[2,0], \"S1\"],\n",
    "        [[2,1], \"C1\"],\n",
    "        [[4,0], \"S2\"],\n",
    "    ],\n",
    "  \"alignments1\": [\n",
    "        [[-1,1], \"w\"],\n",
    "        [[-1,2], \"x\"],\n",
    "        [[-1,3], \"y\"],\n",
    "        [[-1,4], \"z\"],\n",
    "        [[2,0], \"S1\"],\n",
    "        [[2,1], \"C1\"],\n",
    "        [[2,2], \"C2\"],\n",
    "        [[4,0], \"S2\"],\n",
    "        [[4,1], \"C3\"],\n",
    "        [[5,0], \"O\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "num_training_steps_per_epoch =  int(math.ceil(config['train_size']/config['batch_size']))\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466,
     "referenced_widgets": [
      "f4354293ac4343759d9a8b30ae0641ed",
      "8a27be2a519442dd8e4dd9ac473b9b92",
      "5cf89ab0ef634a18a409e4e8c039891c",
      "2dca69565ff14b2a8a9cb9c13abaa004",
      "e66bea1c6d214848a32a193b1b333b2b",
      "74879e26362d4662a75c34d434353199",
      "133996a81a2a4af5b51b82e5deb38601",
      "1de64b1792d94dd8b4497ad15cb6c4f5",
      "5c5d8c460abe44dfb1d80f1e3fb164fa",
      "73feda15263e4217b2643a4ef9ebc426",
      "67729e7d4c9b4d2ca69a509d06765fe2"
     ]
    },
    "id": "HP7Tppzpc6Zv",
    "outputId": "54c26a86-c2f1-43b1-8782-ca429b2712ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.16.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  model_name = 'bert-base-uncased'\n",
    "\n",
    "  bertConfig = transformers.BertConfig.from_pretrained(model_name)\n",
    "  bertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOqvBJ6fJhy9"
   },
   "source": [
    "## Model & optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gJqmGsQkJjep"
   },
   "outputs": [],
   "source": [
    "def prepare_training():\n",
    "  model_name = 'bert-base-uncased'\n",
    "\n",
    "  bertConfig = transformers.BertConfig.from_pretrained(model_name)\n",
    "  bertConfig.num_labels = config['highest_number'] * config['digits'] + 1\n",
    "  bertConfig.num_hidden_layers = config['num_hidden_layers']\n",
    "  bertConfig.num_attention_heads = config['num_attention_heads']\n",
    "\n",
    "  tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
    "  # NOTE: did it initialize the weights from the model_name?\n",
    "  model = transformers.BertForSequenceClassification(bertConfig)\n",
    "\n",
    "  model.to(device);\n",
    "\n",
    "  optimizer = transformers.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "  lr_scheduler = transformers.get_scheduler(\"linear\", optimizer=optimizer,num_warmup_steps=config['num_warmup_steps'], num_training_steps=num_training_steps_per_epoch*config['num_epochs'])\n",
    "\n",
    "  return model, tokenizer, optimizer, lr_scheduler\n",
    "\n",
    "def prepare_training2():\n",
    "  model_name = 'bert-base-uncased'\n",
    "\n",
    "  bertConfig = transformers.BertConfig.from_pretrained(model_name)\n",
    "  bertConfig.num_labels = config['highest_number'] * config['digits'] + 1\n",
    "  bertConfig.T2_num_labels = config['highest_number'] * (config['digits']-1) + 1\n",
    "  bertConfig.num_hidden_layers = config['num_hidden_layers']\n",
    "  bertConfig.num_attention_heads = config['num_attention_heads']\n",
    "\n",
    "  tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
    "  # NOTE: did it initialize the weights from the model_name?\n",
    "  model = BertForMultiSequenceClassification(bertConfig)\n",
    "\n",
    "  model.to(device);\n",
    "\n",
    "  optimizer = transformers.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "  lr_scheduler = transformers.get_scheduler(\"linear\", optimizer=optimizer,num_warmup_steps=config['num_warmup_steps'], num_training_steps=num_training_steps_per_epoch*config['num_epochs'])\n",
    "\n",
    "  return model, tokenizer, optimizer, lr_scheduler\n",
    "\n",
    "def prepare_training3():\n",
    "  model_name = 'bert-base-uncased'\n",
    "\n",
    "  bertConfig = transformers.BertConfig.from_pretrained(model_name)\n",
    "  bertConfig.num_labels = config['highest_number'] * config['digits'] + 1\n",
    "  bertConfig.T2_num_labels = config['highest_number'] * (config['digits']-1) + 1\n",
    "  bertConfig.num_hidden_layers = config['num_hidden_layers']\n",
    "  bertConfig.num_attention_heads = config['num_attention_heads']\n",
    "\n",
    "  tokenizer = transformers.BertTokenizer.from_pretrained(model_name)\n",
    "  # NOTE: did it initialize the weights from the model_name?\n",
    "  neural_model = InterventionableTransformer(BertForMultiSequenceClassification(bertConfig))\n",
    "  causal_model = Interventionable2(CausalArithmetic2(config))\n",
    "\n",
    "  neural_model.model.to(device);\n",
    "  causal_model.model.to(device);\n",
    "\n",
    "  optimizer = transformers.AdamW(neural_model.model.parameters(), lr=config['learning_rate'])\n",
    "  lr_scheduler = transformers.get_scheduler(\"linear\", optimizer=optimizer,num_warmup_steps=config['num_warmup_steps'], num_training_steps=num_training_steps_per_epoch*config['num_epochs'])\n",
    "\n",
    "  return neural_model, causal_model, tokenizer, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIhakieOG9vu"
   },
   "source": [
    "## Define dataset and helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "PoZ8vdjkG7Wb"
   },
   "outputs": [],
   "source": [
    "def get_dataset(digits=4, highest_number=33, size=30):\n",
    "  x_numbers = np.random.randint(low=0, high=highest_number, size=(size,digits))\n",
    "  y = np.sum(x_numbers, axis=1)\n",
    "\n",
    "  def list_to_sentence(ls):\n",
    "    return \" \".join([str(i) for i in ls])\n",
    "\n",
    "  x_sentences = [list_to_sentence(ls) for ls in x_numbers]\n",
    "  \n",
    "  return x_sentences, y\n",
    "\n",
    "def get_dataset2(digits=4, highest_number=33, size=30):\n",
    "  x_numbers = np.random.randint(low=0, high=highest_number, size=(size,digits))\n",
    "  y = np.sum(x_numbers, axis=1)\n",
    "  y2 = np.sum(x_numbers[:,:3], axis=1)\n",
    "\n",
    "  def list_to_sentence(ls):\n",
    "    return \" \".join([str(i) for i in ls])\n",
    "\n",
    "  x_sentences = [list_to_sentence(ls) for ls in x_numbers]\n",
    "  \n",
    "  return x_sentences, y, y2\n",
    "\n",
    "def get_dataset3(digits=4, highest_number=33, size=30):\n",
    "  x_numbers = np.random.randint(low=0, high=highest_number, size=(size,digits))\n",
    "  y = np.sum(x_numbers, axis=1)\n",
    "  y2 = np.sum(x_numbers[:,:3], axis=1)\n",
    "\n",
    "  def list_to_sentence(ls):\n",
    "    return \" \".join([str(i) for i in ls])\n",
    "\n",
    "  x_sentences = [list_to_sentence(ls) for ls in x_numbers]\n",
    "  \n",
    "  return x_numbers, x_sentences, y, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "x6Yyye0Xx9pY"
   },
   "outputs": [],
   "source": [
    "def tokenize_sample(x, y, tokenizer):\n",
    "  x = tokenizer(list(x), return_tensors='pt').to(device)\n",
    "  y = y.long().to(device)\n",
    "\n",
    "  return x, y\n",
    "\n",
    "def tokenize_sample2(x, y, y2, tokenizer):\n",
    "  x = tokenizer(list(x), return_tensors='pt').to(device)\n",
    "  y = y.long().to(device)\n",
    "  y2 = y2.long().to(device)\n",
    "\n",
    "  return x, y, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "lTbg60-uv4D8"
   },
   "outputs": [],
   "source": [
    "class ArithmeticDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, digits=4, highest_number=33, size=30):\n",
    "    super().__init__()\n",
    "\n",
    "    self.size = size\n",
    "    self.x, self.y = get_dataset(digits=digits, highest_number=highest_number, size=size)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.size\n",
    "\n",
    "class ArithmeticDataset2(torch.utils.data.Dataset):\n",
    "  def __init__(self, digits=4, highest_number=33, size=30):\n",
    "    super().__init__()\n",
    "\n",
    "    self.size = size\n",
    "    self.x, self.y, self.y2 = get_dataset2(digits=digits, highest_number=highest_number, size=size)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index], self.y2[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.size\n",
    "\n",
    "class ArithmeticDataset3(torch.utils.data.Dataset):\n",
    "  def __init__(self, digits=4, highest_number=33, size=30):\n",
    "    super().__init__()\n",
    "\n",
    "    self.size = size\n",
    "    self.x_numbers, self.x, self.y, self.y2 = get_dataset3(digits=digits, highest_number=highest_number, size=size)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return  self.x_numbers[index], self.x[index], self.y[index], self.y2[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "9_5RMHK7wgEA"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(ds):\n",
    "  dl = iter(torch.utils.data.DataLoader(ds, batch_size=config['batch_size'], shuffle=True))\n",
    "  return dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfJoMU4tjd0r"
   },
   "source": [
    "## Training stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "oktW8cOslSrC"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(logits, y):\n",
    "  y_hat = torch.argmax(logits, dim=1)\n",
    "  correct = sum(y_hat == y)\n",
    "  acc = correct / len(y_hat) * 100\n",
    "  return acc\n",
    "\n",
    "def train_step(loss, optimizer, lr_scheduler):\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  lr_scheduler.step()\n",
    "\n",
    "def train_log(epoch, step, loss, lr, pbar, logits, y):\n",
    "  # print(f'{step:04}: {loss.item()}')\n",
    "  wandb.log({\"train loss\": loss})\n",
    "  wandb.log({\"learning rate\": lr})\n",
    "\n",
    "  acc = get_accuracy(logits, y)\n",
    "  wandb.log({\"train acc\": acc})\n",
    "\n",
    "\n",
    "  pbar.set_postfix(loss=loss.item(), step=step)\n",
    "\n",
    "def train_log2(epoch, step, loss1, loss2, lr, pbar, logits1, logits2, y1, y2):\n",
    "  # print(f'{step:04}: {loss.item()}')\n",
    "  wandb.log({\"T1 train loss\": loss1})\n",
    "  wandb.log({\"T2 train loss\": loss2})\n",
    "  wandb.log({\"learning rate\": lr})\n",
    "\n",
    "  acc1 = get_accuracy(logits1, y1)\n",
    "  acc2 = get_accuracy(logits2, y2)\n",
    "  wandb.log({\"T1 train acc\": acc1})\n",
    "  wandb.log({\"T2 train acc\": acc2})\n",
    "\n",
    "\n",
    "  pbar.set_postfix(loss=loss1.item(), step=step)\n",
    "\n",
    "def train_log3(epoch, step, T1_loss, T2_loss2, iit_loss, lr, pbar, logits1, logits2, y1, y2):\n",
    "  # print(f'{step:04}: {loss.item()}')\n",
    "  wandb.log({\"T1 train loss\": T1_loss})\n",
    "  wandb.log({\"T2 train loss\": T2_loss2})\n",
    "  wandb.log({\"learning rate\": lr})\n",
    "\n",
    "  acc1 = get_accuracy(logits1, y1)\n",
    "  acc2 = get_accuracy(logits2, y2)\n",
    "  wandb.log({\"T1 train acc\": acc1})\n",
    "  wandb.log({\"T2 train acc\": acc2})\n",
    "\n",
    "  wandb.log({\"iit loss\": iit_loss})\n",
    "\n",
    "  pbar.set_postfix(loss=T1_loss.item(), step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TNFgmBV0oxMA"
   },
   "outputs": [],
   "source": [
    "def split_input_dict(input_dict, halfway_point):\n",
    "  first_half = {}\n",
    "  second_half = {}\n",
    "  for k,v in input_dict.items():\n",
    "    first_half[k] = v[:halfway_point]\n",
    "    second_half[k] = v[halfway_point:2*halfway_point]\n",
    "  return first_half, second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "uR99OrDa0RdM"
   },
   "outputs": [],
   "source": [
    "def eval(model, tokenizer, test_ds):\n",
    "  model.eval()\n",
    "\n",
    "  eval_loss = 0.0\n",
    "  eval_acc = 0.0\n",
    "  test_dl = get_dataloader(test_ds)\n",
    "\n",
    "  for step in range(len(test_dl)):\n",
    "      x , y = test_dl.next()\n",
    "      x, y = tokenize_sample(x,y,tokenizer)\n",
    "\n",
    "      output = model(**x, labels=y)\n",
    "\n",
    "      eval_loss += output.loss.item()\n",
    "      eval_acc += get_accuracy(output.logits, y)\n",
    "\n",
    "  eval_loss /= len(test_dl)\n",
    "  eval_acc /= len(test_dl)\n",
    "\n",
    "  wandb.log({\"test loss\": eval_loss})\n",
    "  wandb.log({\"test acc\": eval_acc})\n",
    "\n",
    "  model.train()\n",
    "\n",
    "def eval2(model, tokenizer, test_ds):\n",
    "  model.eval()\n",
    "\n",
    "  eval_loss1 = 0.0\n",
    "  eval_acc1 = 0.0\n",
    "  eval_loss2 = 0.0\n",
    "  eval_acc2 = 0.0\n",
    "  test_dl = get_dataloader(test_ds)\n",
    "\n",
    "  for step in range(len(test_dl)):\n",
    "      x , y, y2 = test_dl.next()\n",
    "      x, y, y2 = tokenize_sample2(x,y,y2,tokenizer)\n",
    "\n",
    "      output1, output2 = model(**x, labels=y, labels2=y2)\n",
    "\n",
    "      eval_loss1 += output1.loss.item()\n",
    "      eval_acc1 += get_accuracy(output1.logits, y)\n",
    "      eval_loss2 += output2.loss.item()\n",
    "      eval_acc2 += get_accuracy(output2.logits, y2)\n",
    "\n",
    "  eval_loss1 /= len(test_dl)\n",
    "  eval_acc1 /= len(test_dl)\n",
    "  eval_loss2 /= len(test_dl)\n",
    "  eval_acc2 /= len(test_dl)\n",
    "\n",
    "  wandb.log({\"T1 test loss\": eval_loss1})\n",
    "  wandb.log({\"T1 test acc\": eval_acc1})\n",
    "  wandb.log({\"T2 test loss\": eval_loss2})\n",
    "  wandb.log({\"T2 test acc\": eval_acc2})\n",
    "\n",
    "  model.train()\n",
    "\n",
    "def eval3(model, tokenizer, test_ds):\n",
    "  model.eval()\n",
    "\n",
    "  eval_loss1 = 0.0\n",
    "  eval_acc1 = 0.0\n",
    "  eval_loss2 = 0.0\n",
    "  eval_acc2 = 0.0\n",
    "  test_dl = get_dataloader(test_ds)\n",
    "\n",
    "  for step in range(len(test_dl)):\n",
    "      _, x , y, y2 = test_dl.next()\n",
    "      x, y, y2 = tokenize_sample2(x,y,y2,tokenizer)\n",
    "\n",
    "      output1, output2 = model(**x, labels=y, labels2=y2)\n",
    "\n",
    "      eval_loss1 += output1.loss.item()\n",
    "      eval_acc1 += get_accuracy(output1.logits, y)\n",
    "      eval_loss2 += output2.loss.item()\n",
    "      eval_acc2 += get_accuracy(output2.logits, y2)\n",
    "\n",
    "  eval_loss1 /= len(test_dl)\n",
    "  eval_acc1 /= len(test_dl)\n",
    "  eval_loss2 /= len(test_dl)\n",
    "  eval_acc2 /= len(test_dl)\n",
    "\n",
    "  wandb.log({\"T1 test loss\": eval_loss1})\n",
    "  wandb.log({\"T1 test acc\": eval_acc1})\n",
    "  wandb.log({\"T2 test loss\": eval_loss2})\n",
    "  wandb.log({\"T2 test acc\": eval_acc2})\n",
    "\n",
    "  model.train()\n",
    "\n",
    "def ii_accuracy(neural_model, causal_model, tokenizer, test_ds, alignment, task=\"1\"):\n",
    "  neural_model.model.eval()\n",
    "\n",
    "  neural_node, causal_node = alignment\n",
    "  test_dl = get_dataloader(test_ds)\n",
    "\n",
    "  n = []\n",
    "  correct = []\n",
    "  for i in range(len(test_dl)):\n",
    "    x_numbers, x, y, y2 = test_dl.next()\n",
    "    x , y, y2= tokenize_sample2(x, y, y2,tokenizer)\n",
    "\n",
    "    # split in source and base input\n",
    "    halfway_point = math.floor(x['input_ids'].shape[0]/2)\n",
    "\n",
    "    x_numbers_base, x_numbers_source = x_numbers[:halfway_point], x_numbers[halfway_point:2*halfway_point]\n",
    "    x_base, x_source = split_input_dict(x, halfway_point)\n",
    "    y_base, y_source = y[:halfway_point], y[halfway_point:2*halfway_point] \n",
    "    y2_base, y2_source = y2[:halfway_point], y2[halfway_point:2*halfway_point] \n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if task == '1':\n",
    "            _, _, predict_intervention, _, _, _ = neural_model.forward(\n",
    "                x_source, x_base, neural_node)\n",
    "            _, _, target_intervention, _, _, _ = causal_model.forward(\n",
    "                x_numbers_source, x_numbers_base, causal_node)\n",
    "        if task == '2':\n",
    "            _, _, _, _, _, predict_intervention = neural_model.forward(\n",
    "                x_source, x_base, neural_node)\n",
    "            _, _, _, _, _, target_intervention = causal_model.forward(\n",
    "                x_numbers_source, x_numbers_base, causal_node)\n",
    "\n",
    "        predict_labels = torch.argmax(predict_intervention.logits, dim=1).cpu()\n",
    "\n",
    "        correct.append(sum(predict_labels == target_intervention))\n",
    "        n.append(halfway_point)\n",
    "    \n",
    "    correct = np.sum(correct)\n",
    "    acc = 100 * correct / np.sum(n)\n",
    "\n",
    "    neural_model.model.train()\n",
    "\n",
    "    return correct, acc\n",
    "    \n",
    "def eval_ii(neural_model, causal_model, tokenizer, test_ds, config):\n",
    "  for alignment in config['alignments1']:\n",
    "    correct, acc = ii_accuracy(neural_model, causal_model, tokenizer, test_ds, alignment, task=\"1\")\n",
    "    wandb.log({f\"T1 ii  accuracy {alignment}\": acc})\n",
    "  for alignment in config['alignments2']:\n",
    "    correct, acc = ii_accuracy(neural_model, causal_model, tokenizer, test_ds, alignment, task=\"2\")\n",
    "    wandb.log({f\"T2 ii  accuracy {alignment}\": acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "iM7v8c8tjhUK"
   },
   "outputs": [],
   "source": [
    "def train(model, tokenizer, optimizer, lr_scheduler, train_ds, test_ds):\n",
    "  model.train()\n",
    "\n",
    "  global_steps = 0\n",
    "  for epoch in range(config['num_epochs']):\n",
    "\n",
    "    train_dl = get_dataloader(train_ds)\n",
    "\n",
    "    pbar = tqdm.trange(num_training_steps_per_epoch, unit=\"steps\", position=0, leave=True)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "    for step in range(len(train_dl)):\n",
    "      x , y = train_dl.next()\n",
    "      x, y = tokenize_sample(x,y,tokenizer)\n",
    "\n",
    "      output = model(**x, labels=y)\n",
    "\n",
    "      train_step(output.loss, optimizer, lr_scheduler)\n",
    "\n",
    "      train_log(epoch, step, output.loss, lr_scheduler.get_last_lr()[0], pbar, output.logits, y)\n",
    "\n",
    "      pbar.update(1)\n",
    "      \n",
    "      if global_steps % config['eval_freq'] == 0:\n",
    "        eval(model, tokenizer, test_ds)\n",
    "      \n",
    "      global_steps += 1\n",
    "\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "def train2(model, tokenizer, optimizer, lr_scheduler, train_ds, test_ds):\n",
    "  model.train()\n",
    "\n",
    "  global_steps = 0\n",
    "  for epoch in range(config['num_epochs']):\n",
    "\n",
    "    train_dl = get_dataloader(train_ds)\n",
    "\n",
    "    pbar = tqdm.trange(num_training_steps_per_epoch, unit=\"steps\", position=0, leave=True)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "    for step in range(len(train_dl)):\n",
    "      x , y, y2 = train_dl.next()\n",
    "      x , y, y2= tokenize_sample2(x , y, y2,tokenizer)\n",
    "\n",
    "      output1, output2 = model(**x, labels=y, labels2=y2)\n",
    "\n",
    "      train_step(output1.loss + output2.loss, optimizer, lr_scheduler)\n",
    "\n",
    "      train_log2(epoch, step, output1.loss, output2.loss, lr_scheduler.get_last_lr()[0], pbar, output1.logits, output2.logits, y, y2)\n",
    "\n",
    "      pbar.update(1)\n",
    "      \n",
    "      if global_steps % config['eval_freq'] == 0:\n",
    "        eval2(model, tokenizer, test_ds)\n",
    "      \n",
    "      global_steps += 1\n",
    "\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "def train3(neural_model, causal_model, tokenizer, optimizer, lr_scheduler, train_ds, test_ds):\n",
    "  neural_model.model.train()\n",
    "\n",
    "  loss_fct = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  global_steps = 0\n",
    "  for epoch in range(config['num_epochs']):\n",
    "\n",
    "    train_dl = get_dataloader(train_ds)\n",
    "\n",
    "    pbar = tqdm.trange(num_training_steps_per_epoch, unit=\"steps\", position=0, leave=True)\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "    for step in range(len(train_dl)):\n",
    "      x_numbers, x , y, y2 = train_dl.next()\n",
    "      x_numbers = x_numbers.to(device)\n",
    "      x , y, y2= tokenize_sample2(x, y, y2,tokenizer)\n",
    "\n",
    "      # split in source and base input\n",
    "      halfway_point = math.floor(x['input_ids'].shape[0]/2)\n",
    "\n",
    "      x_numbers_base, x_numbers_source = x_numbers[:halfway_point], x_numbers[halfway_point:2*halfway_point]\n",
    "      x_base, x_source = split_input_dict(x, halfway_point)\n",
    "      y_base, y_source = y[:halfway_point], y[halfway_point:2*halfway_point] \n",
    "      y2_base, y2_source = y2[:halfway_point], y2[halfway_point:2*halfway_point] \n",
    "\n",
    "      # sample alignment\n",
    "      neural_node, causal_node = random.choice(config['alignments2'])\n",
    "\n",
    "      # run intervention\n",
    "      source_logits_T1, base_logits_T1, _, source_logits_T2, base_logits_T2, counterfactual_logits_T2 = neural_model.forward(x_source, x_base, neural_node)\n",
    "      with torch.no_grad():\n",
    "          _, _, _, _, _, counterfactual_target_T2 = causal_model.forward(x_numbers_source, x_numbers_base, causal_node)\n",
    "      # source_logits_T1, source_logits_T2 = neural_model.model(**x_source, labels=y_source, labels2=y2_source)\n",
    "      # base_logits_T1, base_logits_T2 = neural_model.model(**x_base, labels=y_base, labels2=y2_base)\n",
    "\n",
    "      # task loss on all seen examples\n",
    "      T1_logits_all = torch.cat((source_logits_T1.logits, base_logits_T1.logits), dim=0)\n",
    "      y_all = torch.cat((y_source, y_base), dim=0)\n",
    "\n",
    "      T2_logits_all = torch.cat((source_logits_T2.logits, base_logits_T2.logits), dim=0)\n",
    "      y2_all = torch.cat((y2_source, y2_base), dim=0)\n",
    "\n",
    "      # T1_loss = loss_fct(source_logits_T1.logits.view(-1, neural_model.model.config.num_labels), y_source.view(-1)) + \\\n",
    "      #         loss_fct(base_logits_T1.logits.view(-1, neural_model.model.config.num_labels), y_base.view(-1))\n",
    "\n",
    "      # T2_loss = loss_fct(source_logits_T2.logits.view(-1, neural_model.model.T2_num_labels), y2_source.view(-1)) + \\\n",
    "      #         loss_fct(base_logits_T2.logits.view(-1, neural_model.model.T2_num_labels), y2_base.view(-1))\n",
    "\n",
    "      T1_loss = loss_fct(T1_logits_all.view(-1, neural_model.model.config.num_labels), y_all.view(-1)) \n",
    "\n",
    "      T2_loss = loss_fct(T2_logits_all.view(-1, neural_model.model.T2_num_labels), y2_all.view(-1))\n",
    "\n",
    "      # T1_loss = (source_logits_T1.loss + base_logits_T1.loss ) / 2 \n",
    "      # T2_loss = (source_logits_T2.loss + base_logits_T2.loss ) / 2 \n",
    "\n",
    "      # T1_loss = source_logits_T1.loss \n",
    "      # T2_loss = source_logits_T2.loss \n",
    "      \n",
    "      # iit loss\n",
    "      iit_loss = loss_fct(counterfactual_logits_T2.logits, counterfactual_target_T2)\n",
    "      # iit_loss = torch.zeros_like(T1_loss, device=T1_loss.device)\n",
    "    \n",
    "      # TODO: reimplement warmup training better\n",
    "      alpha = min((step+epoch*len(train_dl))/(config['num_warmup_epochs']*len(train_dl)),1.0)\n",
    "      wandb.log({\"alpha\":alpha})\n",
    "      T1_loss = alpha * T1_loss\n",
    "    \n",
    "      train_step(T1_loss + T2_loss + iit_loss, optimizer, lr_scheduler)\n",
    "\n",
    "      # train_log3(epoch, step, T1_loss, T2_loss, iit_loss, lr_scheduler.get_last_lr()[0], pbar, base_logits_T1.logits, base_logits_T2.logits, y_base, y2_base)\n",
    "      train_log3(epoch, step, T1_loss, T2_loss, iit_loss, lr_scheduler.get_last_lr()[0], pbar, source_logits_T1.logits, source_logits_T2.logits, y_source, y2_source)\n",
    "\n",
    "      pbar.update(1)\n",
    "      \n",
    "      if global_steps % config['eval_freq'] == 0:\n",
    "        eval3(neural_model.model, tokenizer, test_ds)\n",
    "        eval_ii(neural_model, causal_model, tokenizer, test_ds, config)\n",
    "      \n",
    "      global_steps += 1\n",
    "\n",
    "\n",
    "    pbar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i9qxbB2jfHD"
   },
   "source": [
    "## Run on the single task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "O-86W0hlHp4f"
   },
   "outputs": [],
   "source": [
    "# wandb.init(project=\"transformer-arithmetic-multiIIT\", entity=\"stanford-causality\", config=config, mode=\"online\")\n",
    "# wandb.config = config\n",
    "\n",
    "# model, tokenizer, optimizer, lr_scheduler = prepare_training()\n",
    "\n",
    "# train_ds = ArithmeticDataset(digits=config['digits'], highest_number=config['highest_number'], size=config['train_size'])\n",
    "# test_ds = ArithmeticDataset(digits=config['digits'], highest_number=config['highest_number'], size=config['test_size'])\n",
    "\n",
    "\n",
    "\n",
    "# train(model, tokenizer, optimizer, lr_scheduler, train_ds, test_ds)\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23x84osKdpG4"
   },
   "source": [
    "## Custom multitask model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "2cFS24qk3FFZ"
   },
   "outputs": [],
   "source": [
    "# option 1: crude\n",
    "# wrap bertforsequenceclassification\n",
    "# add second classification head (no pooling) - TODO:consider removing pooling for sequence output for fairer comparison\n",
    "# https://github.com/frankaging/Causal-Distill-XXS/blob/a704dbcb40440a24ae4415348eddbb9f377d49b4/src/modeling.py#L11 -> BertNOPooler\n",
    "# add new output, define loss\n",
    "\n",
    "# option 2: cleaner\n",
    "# make an analogous class to bertforsequence classification\n",
    "# have a new output class\n",
    "# handle everything where it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "4tEYLQDSfWMO"
   },
   "outputs": [],
   "source": [
    "# option 1:\n",
    "class BertForMultiSequenceClassification(transformers.BertPreTrainedModel):\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "\n",
    "    self.bert = transformers.BertForSequenceClassification(config)\n",
    "\n",
    "    self.T2_num_labels = config.T2_num_labels\n",
    "    self.config = config\n",
    "\n",
    "    classifier_dropout = (\n",
    "        config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "    )\n",
    "    self.dropout2 = torch.nn.Dropout(classifier_dropout)\n",
    "    self.classifier2 = torch.nn.Linear(config.hidden_size, config.T2_num_labels)\n",
    "\n",
    "    # Initialize weights and apply final processing\n",
    "    self.post_init()\n",
    "\n",
    "  def forward(\n",
    "    self,\n",
    "    input_ids=None,\n",
    "    attention_mask=None,\n",
    "    token_type_ids=None,\n",
    "    position_ids=None,\n",
    "    head_mask=None,\n",
    "    inputs_embeds=None,\n",
    "    labels=None,\n",
    "    labels2=None,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    "  ):\n",
    "    return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "    outputs = self.bert(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids,\n",
    "        position_ids=position_ids,\n",
    "        head_mask=head_mask,\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        output_attentions=output_attentions,\n",
    "        labels=labels,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=return_dict,\n",
    "    )\n",
    "\n",
    "\n",
    "    hidden_states = outputs.hidden_states\n",
    "    layers = hidden_states[1:]\n",
    "\n",
    "    position = (4,0)\n",
    "    intermediate_output = layers[position[0]][:,position[1]]\n",
    "\n",
    "    intermediate_output = self.dropout2(intermediate_output)\n",
    "    logits = self.classifier2(intermediate_output)\n",
    "\n",
    "    loss = None\n",
    "    if labels2 is not None:\n",
    "        if self.config.problem_type is None:\n",
    "            if self.T2_num_labels == 1:\n",
    "                self.config.problem_type = \"regression\"\n",
    "            elif self.T2_num_labels > 1 and (labels2.dtype == torch.long or labels2.dtype == torch.int):\n",
    "                self.config.problem_type = \"single_label_classification\"\n",
    "            else:\n",
    "                self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "        if self.config.problem_type == \"regression\":\n",
    "            loss_fct = torch.nn.MSELoss()\n",
    "            if self.T2_num_labels == 1:\n",
    "                loss = loss_fct(logits.squeeze(), labels2.squeeze())\n",
    "            else:\n",
    "                loss = loss_fct(logits, labels2)\n",
    "        elif self.config.problem_type == \"single_label_classification\":\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.T2_num_labels), labels2.view(-1))\n",
    "        elif self.config.problem_type == \"multi_label_classification\":\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels2)\n",
    "\n",
    "    return outputs, transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "        loss=loss,\n",
    "        logits=logits,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zyNSL45GzTAW"
   },
   "source": [
    "## Run on multi task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "iO6X7jNlVYJl"
   },
   "outputs": [],
   "source": [
    "# wandb.init(project=\"transformer-arithmetic-multiIIT\", entity=\"stanford-causality\", config=config, mode=\"disabled\")\n",
    "# wandb.config = config\n",
    "\n",
    "# model, tokenizer, optimizer, lr_scheduler = prepare_training2()\n",
    "\n",
    "# train_ds = ArithmeticDataset2(digits=config['digits'], highest_number=config['highest_number'], size=config['train_size'])\n",
    "# test_ds = ArithmeticDataset2(digits=config['digits'], highest_number=config['highest_number'], size=config['test_size'])\n",
    "\n",
    "# train2(model, tokenizer, optimizer, lr_scheduler, train_ds, test_ds)\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9_6yx11dYRA"
   },
   "source": [
    "## Interventionable transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "19oBjcdtdaAC"
   },
   "outputs": [],
   "source": [
    "class Interventionable2():\n",
    "    # NOTE: can probably be merged with Interventionable1\n",
    "    def __init__(self, model):\n",
    "        self.activation = {}\n",
    "        self.model = model\n",
    "\n",
    "        self.names_to_layers = dict(self.model.named_children())\n",
    "\n",
    "    def _get_activation(self, name):\n",
    "        def hook(model, input, output):\n",
    "            self.activation[name] = output\n",
    "        return hook\n",
    "\n",
    "    def _set_activation(self, name):\n",
    "        def hook(model, input, output):\n",
    "            return self.activation[name]\n",
    "        return hook\n",
    "\n",
    "    def forward(self, source, base, layer_name):\n",
    "        # NOTE: other ways that do not require constantly adding / removing hooks should exist\n",
    "        assert layer_name in self.names_to_layers\n",
    "\n",
    "        # set hook to get activation\n",
    "        get_handler = self.names_to_layers[layer_name].register_forward_hook(\n",
    "            self._get_activation(layer_name))\n",
    "\n",
    "        # get output on source examples (and also capture the activations)\n",
    "        # with torch.no_grad():\n",
    "        #     source_logits = self.model(source)\n",
    "        source_logits_T1, source_logits_T2 = self.model(source)\n",
    "\n",
    "        # remove the handler (don't store activations on base)\n",
    "        get_handler.remove()\n",
    "\n",
    "        # get base logits\n",
    "        base_logits_T1, base_logits_T2 = self.model(base)\n",
    "\n",
    "        # set hook to do the intervention\n",
    "        set_handler = self.names_to_layers[layer_name].register_forward_hook(\n",
    "            self._set_activation(layer_name))\n",
    "\n",
    "        # get counterfactual output on base examples\n",
    "        counterfactual_logits_T1, counterfactual_logits_T2 = self.model(base)\n",
    "\n",
    "        # remove the handler\n",
    "        set_handler.remove()\n",
    "\n",
    "        return source_logits_T1, base_logits_T1, counterfactual_logits_T1, source_logits_T2, base_logits_T2, counterfactual_logits_T2\n",
    "        \n",
    "class InterventionableTransformer():\n",
    "    def __init__(self, model):\n",
    "        self.activation = {}\n",
    "        self.model = model\n",
    "\n",
    "    # these functions are model dependent\n",
    "    # they specify how the coordinate system works\n",
    "    def _coordinate_to_getter(self, coord):\n",
    "        layer, index = coord\n",
    "        def hook(model, input, output):\n",
    "            self.activation[f'{layer}-{index}'] = output[:,index]\n",
    "        if layer == -1:\n",
    "          handler = self.model.bert.bert.embeddings.register_forward_hook(hook)\n",
    "        else:\n",
    "          handler = self.model.bert.bert.encoder.layer[layer].output.register_forward_hook(hook)\n",
    "        return handler\n",
    "\n",
    "    def _coordinate_to_setter(self, coord):\n",
    "        layer, index = coord\n",
    "        def hook(model, input, output):\n",
    "            # NOTE: This might lead to errors about inplace manipulations during the backprop.\n",
    "            output[:,index] = self.activation[f'{layer}-{index}']\n",
    "        if layer == -1:\n",
    "          handler = self.model.bert.bert.embeddings.register_forward_hook(hook)\n",
    "        else:\n",
    "          handler = self.model.bert.bert.encoder.layer[layer].output.register_forward_hook(hook)\n",
    "        return handler\n",
    "\n",
    "\n",
    "    def forward(self, source, base, coord):\n",
    "        # NOTE: other ways that do not require constantly adding / removing hooks should exist\n",
    "\n",
    "        # set hook to get activation\n",
    "        # get_handler = self.names_to_layers[layer_name].register_forward_hook(self._get_activation(layer_name))\n",
    "        get_handler = self._coordinate_to_getter(coord)\n",
    "\n",
    "        # get output on source examples (and also capture the activations)\n",
    "        T1_source_output, T2_source_output = self.model(**source)\n",
    "\n",
    "        # remove the handler (don't store activations on base) \n",
    "        get_handler.remove()\n",
    "\n",
    "        # get base logits\n",
    "        T1_base_output, T2_base_output = self.model(**base)\n",
    "        \n",
    "        # set hook to do the intervention\n",
    "        set_handler = self._coordinate_to_setter(coord)\n",
    "\n",
    "        # get counterfactual output on base examples\n",
    "        assert base['input_ids'].shape == source['input_ids'].shape, f\"shape mismatch! {base['input_ids'].shape}, {source['input_ids'].shape}\"\n",
    "        T1_counterfactual_output, T2_counterfactual_output = self.model(**base)\n",
    "\n",
    "        # remove the handler\n",
    "        set_handler.remove()\n",
    "\n",
    "        return T1_source_output, T1_base_output, T1_counterfactual_output, T2_source_output,  T2_base_output,  T2_counterfactual_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "atuHJWFjdZ2t"
   },
   "outputs": [],
   "source": [
    "class CausalArithmetic2(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.w = torch.nn.Identity()\n",
    "        self.x = torch.nn.Identity()\n",
    "        self.y = torch.nn.Identity()\n",
    "        self.z = torch.nn.Identity()\n",
    "\n",
    "        self.S1 = torch.nn.Identity()\n",
    "        self.S2 = torch.nn.Identity()\n",
    "\n",
    "        self.C1 = torch.nn.Identity()\n",
    "        self.C2 = torch.nn.Identity()\n",
    "        self.C3 = torch.nn.Identity()\n",
    "\n",
    "        self.O = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, input):\n",
    "        w = torch.clone(input[:, 0])\n",
    "        x = torch.clone(input[:, 1])\n",
    "        y = torch.clone(input[:, 2])\n",
    "        z = torch.clone(input[:, 3])\n",
    "\n",
    "        w = self.w(w)\n",
    "        x = self.x(x)\n",
    "        y = self.y(y)\n",
    "        z = self.z(z)\n",
    "\n",
    "        S1 = self.S1(w + x)\n",
    "        C1 = self.C1(y)\n",
    "        C2 = self.C2(z)\n",
    "        S2 = self.S2(S1 + C1)\n",
    "        C3 = self.C3(C2)\n",
    "        O = self.O(S2 + C3)\n",
    "        return O, S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "referenced_widgets": [
      "61adb6394244412dafdbaa6e36afc923",
      "effaac526b0a45418c54512363a9d91b",
      "a0db3d02c1c548a7af4055072440d191",
      "26929c9bb46747b181c2b80a94bae329",
      "02b8f23484864b5383c9acc3c7f10516",
      "5336b135ae3e4cfbae235cb635234e4f",
      "16a768efc1e440d7b6b8dba0cb86a33a",
      "eca94910e727482c811da3be5098bf94",
      "34b6a386ae894058bba0e513df31cb03",
      "8c49539019334481b7948307295f8ada",
      "9746b41d9318478088d335cf87af8678",
      "66381b986a304089a87bee115d726938",
      "214ae2e0c7a948fba96d9707db345279",
      "93ecc5f7ab354645a89d6240301537be",
      "3f6134d8467d4b84bf9ad691e38c249a",
      "4c8a67b896f94e9ab15785e1d79e0e59",
      "67c585fb6fd64aaaa82f81745ee52510",
      "8950f56ee85345038bce7fd31476a7af",
      "dedc7ca7690e4f238a8299cbb00cdab1",
      "4fa88984caa74087bb67b7ebc19bd75c",
      "44b3e84a08c848a38a81a88ff153b30e",
      "d48370fff7d5464298a94abe9e56e9f1",
      "73c5e7fcb55b4cc8ab494e9fca92f290",
      "f6589f39cbf247b197ff07923c2b2bc7",
      "748f2b30f5a941448ee483e9829b0870",
      "d299b5b995b7459987ce23f39c9688fa",
      "7b9a61506413436ebfd5a9a897934ab5",
      "1cbff441b54f4c8fac0b0a67389f566a",
      "9dbc90b10bdb4f94bcc0a2a03fb73573",
      "7762cc31d2254fabae486b4fb68dc620",
      "f4bbe28778d345259238f3445c2c373f",
      "fc3887d586e4413f8ed02fb4984f2b65",
      "ba52734021344b23b433d945c4a71dee"
     ]
    },
    "id": "Q_q_e5EsiA_V",
    "outputId": "eb88a40e-5482-4c20-a472-9c4e7ee8c8ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/stanford-causality/transformer-arithmetic-multiIIT/runs/2s403yhw\" target=\"_blank\">dark-jazz-77</a></strong> to <a href=\"https://wandb.ai/stanford-causality/transformer-arithmetic-multiIIT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|██████████| 157/157 [00:10<00:00, 14.69steps/s, loss=0.108, step=156] \n",
      "Epoch 1: 100%|██████████| 157/157 [00:10<00:00, 15.58steps/s, loss=0.176, step=156]\n",
      "Epoch 2: 100%|██████████| 157/157 [00:10<00:00, 15.65steps/s, loss=0.251, step=156]\n",
      "Epoch 3: 100%|██████████| 157/157 [00:10<00:00, 15.60steps/s, loss=0.292, step=156]\n",
      "Epoch 4: 100%|██████████| 157/157 [00:10<00:00, 15.51steps/s, loss=0.359, step=156]\n",
      "Epoch 5: 100%|██████████| 157/157 [00:10<00:00, 15.17steps/s, loss=0.479, step=156]\n",
      "Epoch 6: 100%|██████████| 157/157 [00:10<00:00, 15.42steps/s, loss=0.495, step=156]\n",
      "Epoch 7: 100%|██████████| 157/157 [00:10<00:00, 14.89steps/s, loss=0.516, step=156]\n",
      "Epoch 8: 100%|██████████| 157/157 [00:10<00:00, 15.63steps/s, loss=0.608, step=156]\n",
      "Epoch 9: 100%|██████████| 157/157 [00:10<00:00, 15.46steps/s, loss=0.605, step=156]\n",
      "Epoch 10: 100%|██████████| 157/157 [00:09<00:00, 15.73steps/s, loss=0.635, step=156]\n",
      "Epoch 11: 100%|██████████| 157/157 [00:10<00:00, 15.61steps/s, loss=0.7, step=156]  \n",
      "Epoch 12: 100%|██████████| 157/157 [00:10<00:00, 15.57steps/s, loss=0.804, step=156]\n",
      "Epoch 13: 100%|██████████| 157/157 [00:10<00:00, 15.51steps/s, loss=0.801, step=156]\n",
      "Epoch 14: 100%|██████████| 157/157 [00:10<00:00, 14.78steps/s, loss=0.748, step=156]\n",
      "Epoch 15: 100%|██████████| 157/157 [00:10<00:00, 15.58steps/s, loss=0.826, step=156]\n",
      "Epoch 16: 100%|██████████| 157/157 [00:10<00:00, 15.65steps/s, loss=0.96, step=156] \n",
      "Epoch 17: 100%|██████████| 157/157 [00:10<00:00, 15.39steps/s, loss=0.937, step=156]\n",
      "Epoch 18: 100%|██████████| 157/157 [00:10<00:00, 15.34steps/s, loss=1.12, step=156] \n",
      "Epoch 19: 100%|██████████| 157/157 [00:10<00:00, 15.38steps/s, loss=1.05, step=156] \n",
      "Epoch 20: 100%|██████████| 157/157 [00:10<00:00, 15.55steps/s, loss=1.19, step=156] \n",
      "Epoch 21: 100%|██████████| 157/157 [00:10<00:00, 14.36steps/s, loss=1.1, step=156]  \n",
      "Epoch 22: 100%|██████████| 157/157 [00:10<00:00, 15.43steps/s, loss=0.99, step=156] \n",
      "Epoch 23: 100%|██████████| 157/157 [00:10<00:00, 15.33steps/s, loss=1.09, step=156]\n",
      "Epoch 24: 100%|██████████| 157/157 [00:10<00:00, 15.52steps/s, loss=1.15, step=156]\n",
      "Epoch 25: 100%|██████████| 157/157 [00:10<00:00, 15.57steps/s, loss=1.25, step=156]\n",
      "Epoch 26: 100%|██████████| 157/157 [00:10<00:00, 15.09steps/s, loss=1.34, step=156]\n",
      "Epoch 27: 100%|██████████| 157/157 [00:10<00:00, 15.43steps/s, loss=1.27, step=156]\n",
      "Epoch 28: 100%|██████████| 157/157 [00:10<00:00, 14.85steps/s, loss=1.53, step=156]\n",
      "Epoch 29: 100%|██████████| 157/157 [00:10<00:00, 15.24steps/s, loss=1.7, step=156] \n",
      "Epoch 30: 100%|██████████| 157/157 [00:10<00:00, 15.46steps/s, loss=1.16, step=156]\n",
      "Epoch 31: 100%|██████████| 157/157 [00:10<00:00, 15.32steps/s, loss=1.12, step=156]\n",
      "Epoch 32: 100%|██████████| 157/157 [00:10<00:00, 15.48steps/s, loss=1.44, step=156]\n",
      "Epoch 33: 100%|██████████| 157/157 [00:10<00:00, 14.97steps/s, loss=1.38, step=156]\n",
      "Epoch 34: 100%|██████████| 157/157 [00:10<00:00, 15.46steps/s, loss=1.36, step=156]\n",
      "Epoch 35: 100%|██████████| 157/157 [00:10<00:00, 14.64steps/s, loss=1.45, step=156]\n",
      "Epoch 36: 100%|██████████| 157/157 [00:10<00:00, 15.18steps/s, loss=1.99, step=156]\n",
      "Epoch 37: 100%|██████████| 157/157 [00:10<00:00, 15.41steps/s, loss=1.49, step=156]\n",
      "Epoch 38: 100%|██████████| 157/157 [00:10<00:00, 15.43steps/s, loss=1.84, step=156]\n",
      "Epoch 39: 100%|██████████| 157/157 [00:10<00:00, 15.51steps/s, loss=2, step=156]   \n",
      "Epoch 40: 100%|██████████| 157/157 [00:10<00:00, 15.60steps/s, loss=2.39, step=156]\n",
      "Epoch 41: 100%|██████████| 157/157 [00:09<00:00, 15.79steps/s, loss=1.2, step=156] \n",
      "Epoch 42: 100%|██████████| 157/157 [00:10<00:00, 14.81steps/s, loss=1.19, step=156]\n",
      "Epoch 43: 100%|██████████| 157/157 [00:10<00:00, 15.51steps/s, loss=1.23, step=156]\n",
      "Epoch 44: 100%|██████████| 157/157 [00:10<00:00, 15.54steps/s, loss=1.33, step=156]\n",
      "Epoch 45: 100%|██████████| 157/157 [00:10<00:00, 15.09steps/s, loss=1.69, step=156]\n",
      "Epoch 46: 100%|██████████| 157/157 [00:10<00:00, 15.03steps/s, loss=1.35, step=156]\n",
      "Epoch 47: 100%|██████████| 157/157 [00:10<00:00, 15.28steps/s, loss=1.66, step=156]\n",
      "Epoch 48: 100%|██████████| 157/157 [00:10<00:00, 15.47steps/s, loss=1.34, step=156]\n",
      "Epoch 49: 100%|██████████| 157/157 [00:10<00:00, 14.95steps/s, loss=1.4, step=156] \n",
      "Epoch 50: 100%|██████████| 157/157 [00:10<00:00, 14.88steps/s, loss=1.32, step=156]\n",
      "Epoch 51: 100%|██████████| 157/157 [00:10<00:00, 15.38steps/s, loss=1.64, step=156]\n",
      "Epoch 52: 100%|██████████| 157/157 [00:10<00:00, 15.57steps/s, loss=1.45, step=156]\n",
      "Epoch 53: 100%|██████████| 157/157 [00:10<00:00, 15.65steps/s, loss=1.54, step=156]\n",
      "Epoch 54: 100%|██████████| 157/157 [00:10<00:00, 15.44steps/s, loss=1.57, step=156]\n",
      "Epoch 55: 100%|██████████| 157/157 [00:10<00:00, 15.48steps/s, loss=1.32, step=156]\n",
      "Epoch 56: 100%|██████████| 157/157 [00:10<00:00, 15.67steps/s, loss=1.38, step=156]\n",
      "Epoch 57: 100%|██████████| 157/157 [00:10<00:00, 14.94steps/s, loss=1.78, step=156]\n",
      "Epoch 58: 100%|██████████| 157/157 [00:10<00:00, 15.36steps/s, loss=1.25, step=156]\n",
      "Epoch 59: 100%|██████████| 157/157 [00:10<00:00, 15.54steps/s, loss=1.82, step=156]\n",
      "Epoch 60: 100%|██████████| 157/157 [00:10<00:00, 15.64steps/s, loss=1.37, step=156]\n",
      "Epoch 61: 100%|██████████| 157/157 [00:10<00:00, 15.60steps/s, loss=1.6, step=156] \n",
      "Epoch 62: 100%|██████████| 157/157 [00:10<00:00, 15.64steps/s, loss=1.22, step=156]\n",
      "Epoch 63: 100%|██████████| 157/157 [00:09<00:00, 15.81steps/s, loss=1.54, step=156]\n",
      "Epoch 64: 100%|██████████| 157/157 [00:10<00:00, 14.98steps/s, loss=1.34, step=156]\n",
      "Epoch 65: 100%|██████████| 157/157 [00:09<00:00, 15.83steps/s, loss=1.33, step=156]\n",
      "Epoch 66: 100%|██████████| 157/157 [00:09<00:00, 15.70steps/s, loss=1.41, step=156]\n",
      "Epoch 67: 100%|██████████| 157/157 [00:10<00:00, 15.65steps/s, loss=1.06, step=156]\n",
      "Epoch 68: 100%|██████████| 157/157 [00:09<00:00, 15.91steps/s, loss=1.6, step=156] \n",
      "Epoch 69: 100%|██████████| 157/157 [00:10<00:00, 15.58steps/s, loss=1.3, step=156] \n",
      "Epoch 70: 100%|██████████| 157/157 [00:10<00:00, 15.31steps/s, loss=1.42, step=156]\n",
      "Epoch 71: 100%|██████████| 157/157 [00:10<00:00, 14.90steps/s, loss=1.05, step=156]\n",
      "Epoch 72: 100%|██████████| 157/157 [00:10<00:00, 15.63steps/s, loss=1.01, step=156]\n",
      "Epoch 73: 100%|██████████| 157/157 [00:09<00:00, 15.81steps/s, loss=1.09, step=156]\n",
      "Epoch 74: 100%|██████████| 157/157 [00:10<00:00, 15.67steps/s, loss=1.43, step=156]\n",
      "Epoch 75: 100%|██████████| 157/157 [00:10<00:00, 15.54steps/s, loss=1.11, step=156]\n",
      "Epoch 76: 100%|██████████| 157/157 [00:10<00:00, 15.48steps/s, loss=1.03, step=156] \n",
      "Epoch 77: 100%|██████████| 157/157 [00:10<00:00, 15.67steps/s, loss=1.57, step=156]\n",
      "Epoch 78: 100%|██████████| 157/157 [00:10<00:00, 14.90steps/s, loss=1.42, step=156]\n",
      "Epoch 79: 100%|██████████| 157/157 [00:10<00:00, 15.45steps/s, loss=1.11, step=156]\n",
      "Epoch 80: 100%|██████████| 157/157 [00:10<00:00, 15.55steps/s, loss=1.18, step=156]\n",
      "Epoch 81: 100%|██████████| 157/157 [00:10<00:00, 15.09steps/s, loss=1.03, step=156] \n",
      "Epoch 82: 100%|██████████| 157/157 [00:10<00:00, 15.56steps/s, loss=1.09, step=156] \n",
      "Epoch 83: 100%|██████████| 157/157 [00:10<00:00, 15.60steps/s, loss=1.34, step=156] \n",
      "Epoch 84: 100%|██████████| 157/157 [00:10<00:00, 15.47steps/s, loss=0.927, step=156]\n",
      "Epoch 85: 100%|██████████| 157/157 [00:10<00:00, 14.89steps/s, loss=0.783, step=156]\n",
      "Epoch 86: 100%|██████████| 157/157 [00:10<00:00, 15.69steps/s, loss=1.45, step=156] \n",
      "Epoch 87: 100%|██████████| 157/157 [00:10<00:00, 15.63steps/s, loss=1.07, step=156] \n",
      "Epoch 88: 100%|██████████| 157/157 [00:09<00:00, 15.72steps/s, loss=1.21, step=156] \n",
      "Epoch 89: 100%|██████████| 157/157 [00:10<00:00, 15.67steps/s, loss=1.06, step=156] \n",
      "Epoch 90: 100%|██████████| 157/157 [00:09<00:00, 15.73steps/s, loss=1.24, step=156] \n",
      "Epoch 91: 100%|██████████| 157/157 [00:10<00:00, 15.44steps/s, loss=1.06, step=156] \n",
      "Epoch 92: 100%|██████████| 157/157 [00:10<00:00, 14.95steps/s, loss=1.87, step=156] \n",
      "Epoch 93: 100%|██████████| 157/157 [00:10<00:00, 15.64steps/s, loss=1.05, step=156] \n",
      "Epoch 94: 100%|██████████| 157/157 [00:10<00:00, 15.25steps/s, loss=1.08, step=156] \n",
      "Epoch 95: 100%|██████████| 157/157 [00:10<00:00, 15.66steps/s, loss=0.992, step=156]\n",
      "Epoch 96: 100%|██████████| 157/157 [00:10<00:00, 15.66steps/s, loss=1.24, step=156] \n",
      "Epoch 97: 100%|██████████| 157/157 [00:10<00:00, 15.60steps/s, loss=1.59, step=156] \n",
      "Epoch 98: 100%|██████████| 157/157 [00:10<00:00, 14.77steps/s, loss=1.12, step=156] \n",
      "Epoch 99: 100%|██████████| 157/157 [00:10<00:00, 15.62steps/s, loss=0.642, step=156]\n",
      "Epoch 100: 100%|██████████| 157/157 [00:10<00:00, 14.65steps/s, loss=0.992, step=156]\n",
      "Epoch 101: 100%|██████████| 157/157 [00:10<00:00, 15.43steps/s, loss=1.4, step=156]  \n",
      "Epoch 102: 100%|██████████| 157/157 [00:09<00:00, 15.76steps/s, loss=1.27, step=156] \n",
      "Epoch 103: 100%|██████████| 157/157 [00:10<00:00, 15.29steps/s, loss=0.994, step=156]\n",
      "Epoch 104: 100%|██████████| 157/157 [00:10<00:00, 15.53steps/s, loss=0.944, step=156]\n",
      "Epoch 105: 100%|██████████| 157/157 [00:10<00:00, 15.59steps/s, loss=1.12, step=156] \n",
      "Epoch 106: 100%|██████████| 157/157 [00:10<00:00, 15.44steps/s, loss=1.23, step=156] \n",
      "Epoch 107: 100%|██████████| 157/157 [00:10<00:00, 14.63steps/s, loss=1.5, step=156]  \n",
      "Epoch 108: 100%|██████████| 157/157 [00:10<00:00, 15.41steps/s, loss=1.09, step=156] \n",
      "Epoch 109: 100%|██████████| 157/157 [00:10<00:00, 15.24steps/s, loss=1.25, step=156] \n",
      "Epoch 110: 100%|██████████| 157/157 [00:09<00:00, 15.73steps/s, loss=1.21, step=156] \n",
      "Epoch 111: 100%|██████████| 157/157 [00:09<00:00, 15.70steps/s, loss=0.976, step=156]\n",
      "Epoch 112: 100%|██████████| 157/157 [00:10<00:00, 15.62steps/s, loss=0.891, step=156]\n",
      "Epoch 113: 100%|██████████| 157/157 [00:09<00:00, 15.82steps/s, loss=1.45, step=156] \n",
      "Epoch 114: 100%|██████████| 157/157 [00:10<00:00, 15.01steps/s, loss=0.855, step=156]\n",
      "Epoch 115: 100%|██████████| 157/157 [00:10<00:00, 15.48steps/s, loss=0.723, step=156]\n",
      "Epoch 116: 100%|██████████| 157/157 [00:10<00:00, 15.65steps/s, loss=1.2, step=156]  \n",
      "Epoch 117: 100%|██████████| 157/157 [00:10<00:00, 15.68steps/s, loss=1.18, step=156] \n",
      "Epoch 118: 100%|██████████| 157/157 [00:09<00:00, 15.72steps/s, loss=0.762, step=156]\n",
      "Epoch 119: 100%|██████████| 157/157 [00:09<00:00, 15.77steps/s, loss=1.1, step=156]  \n",
      "Epoch 120: 100%|██████████| 157/157 [00:10<00:00, 15.68steps/s, loss=1.29, step=156] \n",
      "Epoch 121: 100%|██████████| 157/157 [00:10<00:00, 15.08steps/s, loss=1.05, step=156] \n",
      "Epoch 122: 100%|██████████| 157/157 [00:10<00:00, 15.68steps/s, loss=1.19, step=156] \n",
      "Epoch 123: 100%|██████████| 157/157 [00:10<00:00, 15.63steps/s, loss=1.06, step=156] \n",
      "Epoch 124: 100%|██████████| 157/157 [00:09<00:00, 15.70steps/s, loss=1.59, step=156] \n",
      "Epoch 125: 100%|██████████| 157/157 [00:09<00:00, 15.71steps/s, loss=0.856, step=156]\n",
      "Epoch 126: 100%|██████████| 157/157 [00:09<00:00, 15.75steps/s, loss=0.684, step=156]\n",
      "Epoch 127: 100%|██████████| 157/157 [00:10<00:00, 15.58steps/s, loss=0.948, step=156]\n",
      "Epoch 128: 100%|██████████| 157/157 [00:10<00:00, 14.98steps/s, loss=1.17, step=156] \n",
      "Epoch 129: 100%|██████████| 157/157 [00:10<00:00, 14.44steps/s, loss=1.21, step=156] \n",
      "Epoch 130: 100%|██████████| 157/157 [00:10<00:00, 15.42steps/s, loss=1.27, step=156] \n",
      "Epoch 131: 100%|██████████| 157/157 [00:10<00:00, 15.35steps/s, loss=1.46, step=156] \n",
      "Epoch 132: 100%|██████████| 157/157 [00:10<00:00, 15.44steps/s, loss=0.838, step=156]\n",
      "Epoch 133: 100%|██████████| 157/157 [00:10<00:00, 15.64steps/s, loss=1.34, step=156] \n",
      "Epoch 134: 100%|██████████| 157/157 [00:10<00:00, 15.61steps/s, loss=0.984, step=156]\n",
      "Epoch 135: 100%|██████████| 157/157 [00:10<00:00, 14.95steps/s, loss=0.911, step=156]\n",
      "Epoch 136: 100%|██████████| 157/157 [00:10<00:00, 15.61steps/s, loss=0.805, step=156]\n",
      "Epoch 137: 100%|██████████| 157/157 [00:10<00:00, 15.64steps/s, loss=1.19, step=156] \n",
      "Epoch 138: 100%|██████████| 157/157 [00:10<00:00, 15.66steps/s, loss=0.731, step=156]\n",
      "Epoch 139: 100%|██████████| 157/157 [00:10<00:00, 15.62steps/s, loss=1.13, step=156] \n",
      "Epoch 140: 100%|██████████| 157/157 [00:10<00:00, 15.50steps/s, loss=0.72, step=156] \n",
      "Epoch 141: 100%|██████████| 157/157 [00:09<00:00, 15.80steps/s, loss=1.06, step=156] \n",
      "Epoch 142: 100%|██████████| 157/157 [00:10<00:00, 14.93steps/s, loss=1.21, step=156] \n",
      "Epoch 143: 100%|██████████| 157/157 [00:10<00:00, 15.61steps/s, loss=0.987, step=156]\n",
      "Epoch 144: 100%|██████████| 157/157 [00:10<00:00, 15.61steps/s, loss=1.13, step=156] \n",
      "Epoch 145: 100%|██████████| 157/157 [00:09<00:00, 15.77steps/s, loss=0.897, step=156]\n",
      "Epoch 146: 100%|██████████| 157/157 [00:09<00:00, 15.75steps/s, loss=1.2, step=156]  \n",
      "Epoch 147: 100%|██████████| 157/157 [00:09<00:00, 15.74steps/s, loss=0.984, step=156]\n",
      "Epoch 148: 100%|██████████| 157/157 [00:10<00:00, 15.61steps/s, loss=0.76, step=156] \n",
      "Epoch 149: 100%|██████████| 157/157 [00:10<00:00, 15.35steps/s, loss=0.924, step=156]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 221... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>T1 ii  accuracy [[-1, 1], 'w']</td><td>▁▁▃▂▃▂▄▃▄▃▃▅▆▄▄▆▆▃▅▅▆▇▇▇▆▆▆▇▇▇█████▇██▇▇</td></tr><tr><td>T1 ii  accuracy [[-1, 2], 'x']</td><td>▁▁▂▂▅▃▃▃▄▃▄▅▆▅▅▄▅▄▆▄▆▆▆▅▆▆▆▇▇▆▇▇▇▆▇▇█▇██</td></tr><tr><td>T1 ii  accuracy [[-1, 3], 'y']</td><td>▁▂▂▂▄▃▃▃▅▄▄▅▆▅▅▅▆▅▆▅▆▆▇▆▇▆▅▆█▆▇▇██████▇▇</td></tr><tr><td>T1 ii  accuracy [[-1, 4], 'z']</td><td>▁▂▁▂▂▃▄▃▃▄▃▄▅▄▅▅▅▃▆▅▆▇▆▆▆▆▅▇▇▆█▇▇▇▇▇▇███</td></tr><tr><td>T1 ii  accuracy [[2, 0], 'S1']</td><td>▁▁▁▂▃▃▄▃▃▅▄▄▆▅▅▅▆▄▇▅▅▅▄▅▆▆▅▆▇▆▇▇█▆▇▇▇█▇▇</td></tr><tr><td>T1 ii  accuracy [[2, 1], 'C1']</td><td>▁▁▂▃▃▃▅▃▄▅▄▃▆▇▅▂▆▅▄▆█▆▅▅▄▆▄▅▆▅▆▆▃▅▆▅▄▅▄▅</td></tr><tr><td>T1 ii  accuracy [[2, 2], 'C2']</td><td>█▆▆▃▆▆▃▆▃▃▁▁▃▆▃▁▃▃▃▁▆▁█▁▆█▁▃▃▃▁▁▃▃▁▃▁▃▃▆</td></tr><tr><td>T1 ii  accuracy [[4, 0], 'S2']</td><td>▁▂▂▂▄▂▃▄▄▂▄█▆▄▄▃▃▄▄▂▅▃▁▁▄▃▅▃▄▃▂▁▅▃▂▂▂▄▂▃</td></tr><tr><td>T1 ii  accuracy [[4, 1], 'C3']</td><td>▁█▁▆▃▆▆▃▁▆▁▁▆▃▁▁▁▆▁▁▃▆▁▁▃▃▁▁▃█▃▃▃▁▁▁▁▆▃▃</td></tr><tr><td>T1 ii  accuracy [[5, 0], 'O']</td><td>▁▁▁▃▃▄▅▄▄▅▄▆▆▅▆▆▆▃▇▆▇▅▆▇▇▇▇▇█▇▇█▇███████</td></tr><tr><td>T1 test acc</td><td>▁▁▂▃▃▄▄▃▄▄▄▄▆▅▆▅▅▄▆▅▆▇▆▇▆▇▆▇▇▇▇█▇▇██████</td></tr><tr><td>T1 test loss</td><td>█▆▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>T1 train acc</td><td>▁▂▂▃▃▃▅▄▃▄▄▄▅▅▅▆▄▆▆▅▆▆▆▅▅▆▆▅▆█▇▇▅▆█▆▇▇▇▇</td></tr><tr><td>T1 train loss</td><td>▁▂▃▃▅▅▅▆█████▇█▆▇▇▇▇▆▆▆▇▅▅▅▆▅▅▅▅▅▄▄▅▅▄▅▅</td></tr><tr><td>T2 ii  accuracy [[-1, 1], 'w']</td><td>▁▃▂▅▅▄▄▄▅▅▅▆▆▆▇▅▅▆▆█▆▇▇▇█▇▇▇▇███████████</td></tr><tr><td>T2 ii  accuracy [[-1, 2], 'x']</td><td>▁▃▂▃▃▄▄▃▄▅▅▄▆▄▆▆▇▆▇▇▆█▇▇▇███▇▇██▇███████</td></tr><tr><td>T2 ii  accuracy [[-1, 3], 'y']</td><td>▁▂▂▃▃▅▅▃▅▅▆▆▆▅▆▅▆▆▇▆▆▇▆▇▇▇▇█▇█▇█████████</td></tr><tr><td>T2 ii  accuracy [[2, 0], 'S1']</td><td>▁▂▂▃▄▃▄▃▅▃▄▅▅▄▆▆▅▆▇▇▇█▇▇▇▇▇█▇▇███▇██████</td></tr><tr><td>T2 ii  accuracy [[2, 1], 'C1']</td><td>▁▁▂▃▄▃▄▅▅▄▅▅▆▅▆▆▆▇▆▆▇█▇▅█▆▇▇▇▇████▇█████</td></tr><tr><td>T2 ii  accuracy [[4, 0], 'S2']</td><td>▁▁▂▃▄▄▃▃▄▅▅▅▆▄▅▆▆▆▇▇▆▇█▇▇█▇█████████████</td></tr><tr><td>T2 test acc</td><td>▁▂▂▃▄▄▄▃▅▅▅▅▆▅▆▅▆▆▇▆▇▇▇▇██▇█████████████</td></tr><tr><td>T2 test loss</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>T2 train acc</td><td>▁▂▂▂▄▄▂▄▃▅▅▅▄▆▅▅▅▅▆▇▆▆█▆▇▅█▇▇▇█▇▇▇██▇▇██</td></tr><tr><td>T2 train loss</td><td>█▅▅▅▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>alpha</td><td>▁▂▂▃▄▄▅▆▆▇██████████████████████████████</td></tr><tr><td>iit loss</td><td>██▅▅▄▃▃▃▃▃▃▄▃▂▂▂▂▄▂▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>learning rate</td><td>████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>T1 ii  accuracy [[-1, 1], 'w']</td><td>93.75</td></tr><tr><td>T1 ii  accuracy [[-1, 2], 'x']</td><td>96.875</td></tr><tr><td>T1 ii  accuracy [[-1, 3], 'y']</td><td>96.875</td></tr><tr><td>T1 ii  accuracy [[-1, 4], 'z']</td><td>84.375</td></tr><tr><td>T1 ii  accuracy [[2, 0], 'S1']</td><td>90.625</td></tr><tr><td>T1 ii  accuracy [[2, 1], 'C1']</td><td>43.75</td></tr><tr><td>T1 ii  accuracy [[2, 2], 'C2']</td><td>3.125</td></tr><tr><td>T1 ii  accuracy [[4, 0], 'S2']</td><td>6.25</td></tr><tr><td>T1 ii  accuracy [[4, 1], 'C3']</td><td>6.25</td></tr><tr><td>T1 ii  accuracy [[5, 0], 'O']</td><td>100.0</td></tr><tr><td>T1 test acc</td><td>95.07812</td></tr><tr><td>T1 test loss</td><td>0.54705</td></tr><tr><td>T1 train acc</td><td>75.0</td></tr><tr><td>T1 train loss</td><td>0.9237</td></tr><tr><td>T2 ii  accuracy [[-1, 1], 'w']</td><td>100.0</td></tr><tr><td>T2 ii  accuracy [[-1, 2], 'x']</td><td>100.0</td></tr><tr><td>T2 ii  accuracy [[-1, 3], 'y']</td><td>100.0</td></tr><tr><td>T2 ii  accuracy [[2, 0], 'S1']</td><td>96.875</td></tr><tr><td>T2 ii  accuracy [[2, 1], 'C1']</td><td>93.75</td></tr><tr><td>T2 ii  accuracy [[4, 0], 'S2']</td><td>100.0</td></tr><tr><td>T2 test acc</td><td>98.67188</td></tr><tr><td>T2 test loss</td><td>0.29744</td></tr><tr><td>T2 train acc</td><td>75.0</td></tr><tr><td>T2 train loss</td><td>0.56371</td></tr><tr><td>alpha</td><td>1.0</td></tr><tr><td>iit loss</td><td>0.7248</td></tr><tr><td>learning rate</td><td>0.0</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dark-jazz-77</strong>: <a href=\"https://wandb.ai/stanford-causality/transformer-arithmetic-multiIIT/runs/2s403yhw\" target=\"_blank\">https://wandb.ai/stanford-causality/transformer-arithmetic-multiIIT/runs/2s403yhw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220225_043739-2s403yhw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"transformer-arithmetic-multiIIT\", entity=\"stanford-causality\", config=config, mode=\"online\"):\n",
    "  wandb.config = config\n",
    "\n",
    "  neural_model, causal_model, tokenizer, optimizer, lr_scheduler = prepare_training3()\n",
    "\n",
    "  train_ds = ArithmeticDataset3(digits=config['digits'], highest_number=config['highest_number'], size=config['train_size'])\n",
    "  test_ds = ArithmeticDataset3(digits=config['digits'], highest_number=config['highest_number'], size=config['test_size'])\n",
    "\n",
    "  train3(neural_model, causal_model, tokenizer, optimizer, lr_scheduler, train_ds, test_ds)\n",
    "\n",
    "  torch.save(neural_model.model.state_dict(), wandb.run.name + '.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iLlF4vpz5-c"
   },
   "source": [
    "## Bert without a pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "U4JKqC0M2q2l"
   },
   "outputs": [],
   "source": [
    "# class BertModelNoPooler(transformers.BertPreTrainedModel):\n",
    "#     def __init__(self, config):\n",
    "#         super(BertModelNoPooler, self).__init__(config)\n",
    "#         self.embeddings = transformers.BertEmbeddings(config)\n",
    "#         self.encoder = transformers.BertEncoder(config)\n",
    "#         self.apply(self.init_bert_weights)\n",
    "\n",
    "#     def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True):\n",
    "#         if attention_mask is None:\n",
    "#             attention_mask = torch.ones_like(input_ids)\n",
    "#         if token_type_ids is None:\n",
    "#             token_type_ids = torch.zeros_like(input_ids)\n",
    "\n",
    "#         extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "#         extended_attention_mask = extended_attention_mask.to(dtype=next(self.parameters()).dtype) # fp16 compatibility\n",
    "#         extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "#         embedding_output = self.embeddings(input_ids, token_type_ids)\n",
    "#         encoded_layers = self.encoder(embedding_output,\n",
    "#                                       extended_attention_mask,\n",
    "#                                       output_all_encoded_layers=output_all_encoded_layers)\n",
    "#         return encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89hOeNW83OcT",
    "outputId": "d79bbe34-3c74-4f46-bb8f-ac7685f2fcbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_model.model.bert.bert.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Y2Go764irdPm"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(neural_model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TransformerArithmetic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02b8f23484864b5383c9acc3c7f10516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9746b41d9318478088d335cf87af8678",
      "placeholder": "​",
      "style": "IPY_MODEL_8c49539019334481b7948307295f8ada",
      "value": " 28.0/28.0 [00:00&lt;00:00, 608B/s]"
     }
    },
    "133996a81a2a4af5b51b82e5deb38601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16a768efc1e440d7b6b8dba0cb86a33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cbff441b54f4c8fac0b0a67389f566a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1de64b1792d94dd8b4497ad15cb6c4f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "214ae2e0c7a948fba96d9707db345279": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26929c9bb46747b181c2b80a94bae329": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34b6a386ae894058bba0e513df31cb03",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eca94910e727482c811da3be5098bf94",
      "value": 28
     }
    },
    "2dca69565ff14b2a8a9cb9c13abaa004": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c5d8c460abe44dfb1d80f1e3fb164fa",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1de64b1792d94dd8b4497ad15cb6c4f5",
      "value": 570
     }
    },
    "34b6a386ae894058bba0e513df31cb03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f6134d8467d4b84bf9ad691e38c249a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fa88984caa74087bb67b7ebc19bd75c",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dedc7ca7690e4f238a8299cbb00cdab1",
      "value": 231508
     }
    },
    "44b3e84a08c848a38a81a88ff153b30e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c8a67b896f94e9ab15785e1d79e0e59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d48370fff7d5464298a94abe9e56e9f1",
      "placeholder": "​",
      "style": "IPY_MODEL_44b3e84a08c848a38a81a88ff153b30e",
      "value": " 226k/226k [00:00&lt;00:00, 349kB/s]"
     }
    },
    "4fa88984caa74087bb67b7ebc19bd75c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5336b135ae3e4cfbae235cb635234e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c5d8c460abe44dfb1d80f1e3fb164fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cf89ab0ef634a18a409e4e8c039891c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_133996a81a2a4af5b51b82e5deb38601",
      "placeholder": "​",
      "style": "IPY_MODEL_74879e26362d4662a75c34d434353199",
      "value": "Downloading: 100%"
     }
    },
    "61adb6394244412dafdbaa6e36afc923": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0db3d02c1c548a7af4055072440d191",
       "IPY_MODEL_26929c9bb46747b181c2b80a94bae329",
       "IPY_MODEL_02b8f23484864b5383c9acc3c7f10516"
      ],
      "layout": "IPY_MODEL_effaac526b0a45418c54512363a9d91b"
     }
    },
    "66381b986a304089a87bee115d726938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_93ecc5f7ab354645a89d6240301537be",
       "IPY_MODEL_3f6134d8467d4b84bf9ad691e38c249a",
       "IPY_MODEL_4c8a67b896f94e9ab15785e1d79e0e59"
      ],
      "layout": "IPY_MODEL_214ae2e0c7a948fba96d9707db345279"
     }
    },
    "67729e7d4c9b4d2ca69a509d06765fe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67c585fb6fd64aaaa82f81745ee52510": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73c5e7fcb55b4cc8ab494e9fca92f290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_748f2b30f5a941448ee483e9829b0870",
       "IPY_MODEL_d299b5b995b7459987ce23f39c9688fa",
       "IPY_MODEL_7b9a61506413436ebfd5a9a897934ab5"
      ],
      "layout": "IPY_MODEL_f6589f39cbf247b197ff07923c2b2bc7"
     }
    },
    "73feda15263e4217b2643a4ef9ebc426": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74879e26362d4662a75c34d434353199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "748f2b30f5a941448ee483e9829b0870": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9dbc90b10bdb4f94bcc0a2a03fb73573",
      "placeholder": "​",
      "style": "IPY_MODEL_1cbff441b54f4c8fac0b0a67389f566a",
      "value": "Downloading: 100%"
     }
    },
    "7762cc31d2254fabae486b4fb68dc620": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b9a61506413436ebfd5a9a897934ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba52734021344b23b433d945c4a71dee",
      "placeholder": "​",
      "style": "IPY_MODEL_fc3887d586e4413f8ed02fb4984f2b65",
      "value": " 455k/455k [00:00&lt;00:00, 635kB/s]"
     }
    },
    "8950f56ee85345038bce7fd31476a7af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a27be2a519442dd8e4dd9ac473b9b92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c49539019334481b7948307295f8ada": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93ecc5f7ab354645a89d6240301537be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8950f56ee85345038bce7fd31476a7af",
      "placeholder": "​",
      "style": "IPY_MODEL_67c585fb6fd64aaaa82f81745ee52510",
      "value": "Downloading: 100%"
     }
    },
    "9746b41d9318478088d335cf87af8678": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dbc90b10bdb4f94bcc0a2a03fb73573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0db3d02c1c548a7af4055072440d191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16a768efc1e440d7b6b8dba0cb86a33a",
      "placeholder": "​",
      "style": "IPY_MODEL_5336b135ae3e4cfbae235cb635234e4f",
      "value": "Downloading: 100%"
     }
    },
    "ba52734021344b23b433d945c4a71dee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d299b5b995b7459987ce23f39c9688fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4bbe28778d345259238f3445c2c373f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7762cc31d2254fabae486b4fb68dc620",
      "value": 466062
     }
    },
    "d48370fff7d5464298a94abe9e56e9f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dedc7ca7690e4f238a8299cbb00cdab1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e66bea1c6d214848a32a193b1b333b2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67729e7d4c9b4d2ca69a509d06765fe2",
      "placeholder": "​",
      "style": "IPY_MODEL_73feda15263e4217b2643a4ef9ebc426",
      "value": " 570/570 [00:00&lt;00:00, 9.26kB/s]"
     }
    },
    "eca94910e727482c811da3be5098bf94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "effaac526b0a45418c54512363a9d91b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4354293ac4343759d9a8b30ae0641ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5cf89ab0ef634a18a409e4e8c039891c",
       "IPY_MODEL_2dca69565ff14b2a8a9cb9c13abaa004",
       "IPY_MODEL_e66bea1c6d214848a32a193b1b333b2b"
      ],
      "layout": "IPY_MODEL_8a27be2a519442dd8e4dd9ac473b9b92"
     }
    },
    "f4bbe28778d345259238f3445c2c373f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6589f39cbf247b197ff07923c2b2bc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc3887d586e4413f8ed02fb4984f2b65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
