bertConfig = {
    #TODO: clean this up
    # make sure there is no overlap in the naming schemes
    return_dict = true,
    output_hidden_states = false,
    output_attentions = false,
    torchscript = false,
    torch_dtype = null,
    use_bfloat16 = false,
    pruned_heads = {},
    tie_word_embeddings = true,
    is_encoder_decoder = false,
    is_decoder = false,
    cross_attention_hidden_size = null,
    add_cross_attention = false,
    tie_encoder_decoder = false,
    max_length = 20,
    min_length = 0,
    do_sample = false,
    early_stopping = false,
    num_beams = 1,
    num_beam_groups = 1,
    diversity_penalty = 0.0,
    temperature = 1.0,
    top_k = 50,
    top_p = 1.0,
    repetition_penalty = 1.0,
    length_penalty = 1.0,
    no_repeat_ngram_size = 0,
    encoder_no_repeat_ngram_size = 0,
    bad_words_ids = null,
    num_return_sequences = 1,
    chunk_size_feed_forward = 0,
    output_scores = false,
    return_dict_in_generate = false,
    forced_bos_token_id = null,
    forced_eos_token_id = null,
    remove_invalid_values = false,
    architectures = [
        "BertForMaskedLM"
    ],
    finetuning_task = null,
    id2label = {
        "0": "LABEL_0"
    },
    label2id = {
        "LABEL_0": 0
    },
    tokenizer_class = null,
    prefix = null,
    bos_token_id = null,
    pad_token_id = 0,
    eos_token_id = null,
    sep_token_id = null,
    decoder_start_token_id = null,
    task_specific_params = null,
    problem_type = "regression",
    _name_or_path = "",
    transformers_version = "4.16.2",
    gradient_checkpointing = false,
    model_type = "bert",
    vocab_size = 30522,
    hidden_size = 768,
    num_hidden_layers = 12,
    num_attention_heads = 12,
    hidden_act = "gelu",
    intermediate_size = 3072,
    hidden_dropout_prob = 0.1,
    attention_probs_dropout_prob = 0.1,
    max_position_embeddings = 512,
    type_vocab_size = 2,
    initializer_range = 0.02,
    layer_norm_eps = 1e-12,
    position_embedding_type = "absolute",
    use_cache = true,
    classifier_dropout = null
}

base = ${bertConfig}{
    from_pretrained="bert-base-uncased",
    wandb_track="False"
    #TODO: change to transformer-friendly conf
    eval_freq=25,
    # Deterministic behavior
    seed = 42
    # device
    device = "cuda:0"
    # arithmetic dataset parameters
    dataset = "Arithmetic"
    dataset_highest_number = 30
    dataset_train_size = 10000
    dataset_test_size = 1000
    # model hyperparameters
    model_hidden_width = 200    #TODO: remove
    model_hidden_layers = 1     #TODO: remove
    activation = "relu"         #TODO: remove
    # learning
    epochs = 600                #TODO: change
    learning_rate = 5e-5       
    # momentum = 0.9              #TODO: change
    batch_size = 64             #TODO: change
    # neural <-> causal alignment
    iit = "True"
    # alignments1 = [             #TODO: specify in terms of coordinates
    #     ["identity_w", "w"],
    #     ["identity_x", "x"],
    #     ["identity_y", "y"],
    #     ["identity_z", "z"],
    #     ["identity_a", "S1"],
    #     ["identity_b", "C1"],
    #     ["identity_c", "C2"],
    #     ["identity_e", "S2"],
    #     ["identity_g", "C3"],
    #     ["identity_o", "O"]
    # ]
    alignments1 = [             #TODO: specify in terms of coordinates
        [[0,0], "w"],
        [[0,1], "x"],
        [[0,2], "y"],
        [[0,3], "z"],
        [[2,0], "S1"],
        [[2,1], "C1"],
        [[2,2], "C2"],
        [[3,0], "S2"],
        [[3,1], "C3"],
        [[13,0], "O"]
    ]
    alignments2 = [             #TODO: specify in terms of coordinates
        [[0,0], "w"],
        [[0,1], "x"],
        [[0,2], "y"],
        [[0,3], "z"],
        [[2,0], "S1"],
        [[2,1], "C1"],
        [[3,0], "S2"],
    ]
    # alignments2 = [
    #     ["identity_w", "w"],
    #     ["identity_x", "x"],
    #     ["identity_y", "y"],
    #     ["identity_a", "S1"],
    #     ["identity_b", "C1"],
    #     ["identity_e", "S2"],
    # ]
    reg="none"                  #TODO: remove
    reg_alpha=0.0               #TODO: remove
    # T1_delay = 1                #TODO: change
    # T1_warmup = 100             #TODO: change
    num_warmup_steps = 100
}